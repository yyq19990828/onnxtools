# Quick Start: ColorLayerONNXå’ŒOCRONNXé‡æ„

**Feature Branch**: `004-refactor-colorlayeronnx-ocronnx`
**Last Updated**: 2025-10-09

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›é‡æ„åçš„ColorLayerONNXå’ŒOCRONNXç±»çš„å¿«é€Ÿå…¥é—¨æŒ‡å—,åŒ…æ‹¬è¿ç§»å‰åçš„å¯¹æ¯”ã€å¸¸è§ä½¿ç”¨åœºæ™¯å’Œæœ€ä½³å®è·µã€‚

---

## ğŸš€ å¿«é€Ÿå¯¹æ¯”:é‡æ„å‰ vs é‡æ„å

### OCRONNXä½¿ç”¨ç¤ºä¾‹

#### é‡æ„å‰ (v1.0)

```python
# æ—§ç‰ˆæœ¬:ç‹¬ç«‹å®ç°,ä½¿ç”¨infer()æ–¹æ³•
from infer_onnx.ocr_onnx import OCRONNX
import yaml

# åŠ è½½å­—ç¬¦å­—å…¸
with open('configs/plate.yaml') as f:
    config = yaml.safe_load(f)
character = config['plate_dict']['character']

# åˆ›å»ºOCRå®ä¾‹
ocr_model = OCRONNX('models/ocr.onnx')  # è‡ªåŠ¨æ£€æµ‹providers

# æ‰‹åŠ¨é¢„å¤„ç†
from utils.ocr_image_processing import process_plate_image, resize_norm_img
processed_img = process_plate_image(plate_image, is_double_layer=True)
normalized_img = resize_norm_img(processed_img, [48, 320])

# æ‰§è¡Œæ¨ç†(æ—§æ–¹æ³•å)
outputs = ocr_model.infer(normalized_img)

# æ‰‹åŠ¨åå¤„ç†
from utils.ocr_post_processing import decode
text_index = outputs['text_index']
text_prob = outputs['text_prob']
results = decode(character, text_index, text_prob)
```

#### é‡æ„å (v2.0) âœ¨

```python
# æ–°ç‰ˆæœ¬:ç»§æ‰¿BaseOnnx,ç»Ÿä¸€æ¥å£
from infer_onnx import OCRONNX
import yaml

# åŠ è½½å­—ç¬¦å­—å…¸
with open('configs/plate.yaml') as f:
    config = yaml.safe_load(f)
character = config['plate_dict']['character']

# åˆ›å»ºOCRå®ä¾‹(å‚æ•°æ›´æ˜ç¡®)
ocr_model = OCRONNX(
    onnx_path='models/ocr.onnx',
    character=character,           # âœ… å­—ç¬¦å­—å…¸ä½œä¸ºæ„é€ å‚æ•°
    input_shape=(48, 320),         # âœ… æ˜ç¡®è¾“å…¥å°ºå¯¸
    conf_thres=0.5                 # âœ… ç½®ä¿¡åº¦é˜ˆå€¼
)

# ä¸€è¡Œä»£ç å®Œæˆæ¨ç†(é¢„å¤„ç†+æ¨ç†+åå¤„ç†)
results, orig_shape = ocr_model(plate_image, is_double_layer=True)

# ç›´æ¥ä½¿ç”¨ç»“æœ
for text, avg_conf, char_confs in results:
    print(f"Text: {text}, Confidence: {avg_conf:.3f}")
```

**å…³é”®æ”¹è¿›**:
- âœ… **ç»Ÿä¸€æ¥å£**: ä½¿ç”¨`__call__()`æ›¿ä»£`infer()`,ç¬¦åˆPythonæƒ¯ä¾‹
- âœ… **è‡ªåŠ¨å¤„ç†**: å†…éƒ¨å®Œæˆé¢„å¤„ç†å’Œåå¤„ç†,å‡å°‘æ ·æ¿ä»£ç 
- âœ… **å‚æ•°æ˜ç¡®**: å­—ç¬¦å­—å…¸ä½œä¸ºæ„é€ å‚æ•°,é¿å…å¤–éƒ¨ä¾èµ–
- âœ… **æ‡’åŠ è½½**: ç»§æ‰¿BaseOnnx,æ¨¡å‹å»¶è¿ŸåŠ è½½,èŠ‚çœåˆå§‹åŒ–æ—¶é—´

---

### ColorLayerONNXä½¿ç”¨ç¤ºä¾‹

#### é‡æ„å‰ (v1.0)

```python
# æ—§ç‰ˆæœ¬:ç‹¬ç«‹å®ç°,ä½¿ç”¨infer()æ–¹æ³•
from infer_onnx.ocr_onnx import ColorLayerONNX

# åˆ›å»ºé¢œè‰²åˆ†ç±»å™¨
classifier = ColorLayerONNX('models/color_layer.onnx')

# æ‰‹åŠ¨é¢„å¤„ç†
from utils.ocr_image_processing import image_pretreatment
preprocessed_img = image_pretreatment(plate_image, [224, 224])

# æ‰§è¡Œæ¨ç†(æ—§æ–¹æ³•å)
outputs = classifier.infer(preprocessed_img)

# æ‰‹åŠ¨è§£æè¾“å‡º
color_logits = outputs[0]
layer_logits = outputs[1]
color_idx = np.argmax(color_logits)
layer_idx = np.argmax(layer_logits)

# æ‰‹åŠ¨æ˜ å°„åˆ°åç§°
color_map = {0: 'blue', 1: 'yellow', 2: 'white', 3: 'black', 4: 'green'}
layer_map = {0: 'single', 1: 'double'}
color = color_map[color_idx]
layer = layer_map[layer_idx]
```

#### é‡æ„å (v2.0) âœ¨

```python
# æ–°ç‰ˆæœ¬:ç»§æ‰¿BaseOnnx,ç»Ÿä¸€æ¥å£
from infer_onnx import ColorLayerONNX
import yaml

# åŠ è½½æ˜ å°„é…ç½®
with open('configs/plate.yaml') as f:
    config = yaml.safe_load(f)
color_map = config['color_map']
layer_map = config['layer_map']

# åˆ›å»ºåˆ†ç±»å™¨(å‚æ•°æ›´æ˜ç¡®)
classifier = ColorLayerONNX(
    onnx_path='models/color_layer.onnx',
    color_map=color_map,          # âœ… é¢œè‰²æ˜ å°„ä½œä¸ºæ„é€ å‚æ•°
    layer_map=layer_map,          # âœ… å±‚çº§æ˜ å°„ä½œä¸ºæ„é€ å‚æ•°
    input_shape=(224, 224),       # âœ… æ˜ç¡®è¾“å…¥å°ºå¯¸
    conf_thres=0.5
)

# ä¸€è¡Œä»£ç å®Œæˆæ¨ç†(é¢„å¤„ç†+æ¨ç†+åå¤„ç†)
result, orig_shape = classifier(plate_image)

# ç›´æ¥ä½¿ç”¨ç»“æ„åŒ–ç»“æœ
print(f"Color: {result['color']} (conf: {result['color_conf']:.3f})")
print(f"Layer: {result['layer']} (conf: {result['layer_conf']:.3f})")
```

**å…³é”®æ”¹è¿›**:
- âœ… **ç»“æ„åŒ–è¾“å‡º**: è¿”å›å­—å…¸è€Œä¸æ˜¯å…ƒç»„,é”®åæ¸…æ™°
- âœ… **è‡ªåŠ¨æ˜ å°„**: å†…éƒ¨å®Œæˆç´¢å¼•åˆ°åç§°çš„æ˜ å°„,å‡å°‘æ‰‹åŠ¨ä»£ç 
- âœ… **ç½®ä¿¡åº¦å†…ç½®**: è‡ªåŠ¨è®¡ç®—å¹¶è¿”å›softmaxç½®ä¿¡åº¦
- âœ… **ç»Ÿä¸€é£æ ¼**: ä¸OCRONNXå’Œå…¶ä»–æ£€æµ‹å™¨ä¿æŒä¸€è‡´çš„APIé£æ ¼

---

## ğŸ“– å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: ç«¯åˆ°ç«¯è½¦ç‰Œè¯†åˆ«ç®¡é“

```python
import cv2
import yaml
from infer_onnx import OCRONNX, ColorLayerONNX

# åŠ è½½é…ç½®
with open('configs/plate.yaml') as f:
    config = yaml.safe_load(f)

# åˆå§‹åŒ–æ¨¡å‹
ocr_model = OCRONNX(
    'models/ocr.onnx',
    character=config['plate_dict']['character'],
    conf_thres=0.7  # é«˜ç½®ä¿¡åº¦é˜ˆå€¼
)

classifier = ColorLayerONNX(
    'models/color_layer.onnx',
    color_map=config['color_map'],
    layer_map=config['layer_map']
)

# è¯»å–è½¦ç‰Œå›¾åƒ
plate_img = cv2.imread('plate.jpg')

# æ­¥éª¤1: é¢œè‰²å’Œå±‚çº§åˆ†ç±»
color_result, _ = classifier(plate_img)
color = color_result['color']
layer = color_result['layer']
is_double_layer = (layer == 'double')

print(f"Plate Color: {color}")
print(f"Plate Layer: {layer}")

# æ­¥éª¤2: OCRè¯†åˆ«(æ ¹æ®å±‚çº§è‡ªåŠ¨å¤„ç†)
ocr_results, _ = ocr_model(plate_img, is_double_layer=is_double_layer)

# è¾“å‡ºæœ€ç»ˆç»“æœ
if ocr_results:
    text, conf, char_confs = ocr_results[0]
    print(f"Plate Number: {text}")
    print(f"OCR Confidence: {conf:.3f}")
```

**è¾“å‡ºç¤ºä¾‹**:
```
Plate Color: blue
Plate Layer: single
Plate Number: äº¬A12345
OCR Confidence: 0.952
```

---

### åœºæ™¯2: æ‰¹é‡å¤„ç†å¤šå¼ è½¦ç‰Œ

```python
import glob
from pathlib import Path
from tqdm import tqdm

# åˆå§‹åŒ–æ¨¡å‹(å¤ç”¨å®ä¾‹,é¿å…é‡å¤åŠ è½½)
ocr_model = OCRONNX('models/ocr.onnx', character=character)
classifier = ColorLayerONNX('models/color_layer.onnx', color_map=color_map, layer_map=layer_map)

# æ‰¹é‡å¤„ç†
plate_images = glob.glob('plates/*.jpg')
results = []

for img_path in tqdm(plate_images, desc="Processing plates"):
    # è¯»å–å›¾åƒ
    img = cv2.imread(img_path)

    # åˆ†ç±»
    color_result, _ = classifier(img)

    # OCRè¯†åˆ«
    is_double = (color_result['layer'] == 'double')
    ocr_results, _ = ocr_model(img, is_double_layer=is_double)

    # ä¿å­˜ç»“æœ
    if ocr_results:
        text, conf, _ = ocr_results[0]
        results.append({
            'file': Path(img_path).name,
            'color': color_result['color'],
            'layer': color_result['layer'],
            'text': text,
            'confidence': conf
        })

# å¯¼å‡ºä¸ºCSV
import pandas as pd
df = pd.DataFrame(results)
df.to_csv('plate_recognition_results.csv', index=False)
print(f"Processed {len(results)} plates")
```

---

### åœºæ™¯3: TensorRTå¼•æ“ç²¾åº¦å¯¹æ¯”

```python
from infer_onnx import OCRONNX

# åˆ›å»ºONNXæ¨ç†å™¨
ocr_onnx = OCRONNX('models/ocr.onnx', character=character)

# å‡†å¤‡æµ‹è¯•æ•°æ®
dataloader = ocr_onnx.create_engine_dataloader(
    data_dir='test_plates/',
    batch_size=1
)

# å¯¹æ¯”ONNXå’ŒTensorRTå¼•æ“ç²¾åº¦
comparison_result = ocr_onnx.compare_engine(
    engine_path='models/ocr.engine',
    data_loader=dataloader,
    tolerance=1e-3  # å®¹å·®é˜ˆå€¼
)

# è¾“å‡ºå¯¹æ¯”ç»“æœ
print(f"Max Difference: {comparison_result['max_diff']:.6f}")
print(f"Mean Difference: {comparison_result['mean_diff']:.6f}")
print(f"Pass: {comparison_result['pass']}")

if not comparison_result['pass']:
    print(f"âš ï¸ Warning: TensorRT engine accuracy degradation detected!")
```

---

### åœºæ™¯4: é›†æˆåˆ°utils/pipeline.py

#### ä¿®æ”¹å‰ (ä½¿ç”¨ç‹¬ç«‹å‡½æ•°)

```python
# utils/pipeline.py (æ—§ç‰ˆ)
from utils.ocr_image_processing import process_plate_image, resize_norm_img
from utils.ocr_post_processing import decode

# è½¦ç‰Œå¤„ç†æµç¨‹
plate_img = crop_plate(image, bbox)
processed = process_plate_image(plate_img, is_double_layer=True)
normalized = resize_norm_img(processed, [48, 320])
ocr_output = ocr_model.infer(normalized)
results = decode(character, ocr_output['text_index'], ocr_output['text_prob'])
```

#### ä¿®æ”¹å (ä½¿ç”¨ç±»æ–¹æ³•)

```python
# utils/pipeline.py (æ–°ç‰ˆ)
from infer_onnx import OCRONNX

# è½¦ç‰Œå¤„ç†æµç¨‹(ç®€åŒ–ä¸ºä¸€è¡Œ)
plate_img = crop_plate(image, bbox)
results, _ = ocr_model(plate_img, is_double_layer=True)
```

**æˆ–è€…ä½¿ç”¨é™æ€æ–¹æ³• (å¦‚æœéœ€è¦ç‹¬ç«‹è°ƒç”¨é¢„å¤„ç†)**:

```python
# utils/pipeline.py (ä½¿ç”¨é™æ€æ–¹æ³•)
from infer_onnx.ocr_onnx import OCRONNX

# ä»…é¢„å¤„ç†(ä¸æ¨ç†)
processed = OCRONNX._process_plate_image_static(plate_img, is_double_layer=True)
normalized = OCRONNX._resize_norm_img_static(processed, (48, 320))

# åç»­æ¨ç†
results, _ = ocr_model(normalized)
```

---

## ğŸ”§ è¿ç§»æŒ‡å—

### æ­¥éª¤1: æ›´æ–°å¯¼å…¥è¯­å¥

```python
# æ—§ç‰ˆ
from infer_onnx.ocr_onnx import OCRONNX, ColorLayerONNX
from utils.ocr_image_processing import process_plate_image, resize_norm_img, image_pretreatment
from utils.ocr_post_processing import decode

# æ–°ç‰ˆ
from infer_onnx import OCRONNX, ColorLayerONNX
# âœ… ä¸å†éœ€è¦å¯¼å…¥utilsä¸­çš„å‡½æ•°
```

### æ­¥éª¤2: æ›´æ–°æ¨¡å‹åˆå§‹åŒ–

```python
# æ—§ç‰ˆ
ocr_model = OCRONNX('models/ocr.onnx')

# æ–°ç‰ˆ(æ·»åŠ å¿…éœ€å‚æ•°)
ocr_model = OCRONNX(
    onnx_path='models/ocr.onnx',
    character=character,  # âœ… å¿…éœ€å‚æ•°
    input_shape=(48, 320)
)
```

### æ­¥éª¤3: æ›´æ–°æ¨ç†è°ƒç”¨

```python
# æ—§ç‰ˆ
outputs = ocr_model.infer(preprocessed_image)

# æ–°ç‰ˆ
results, orig_shape = ocr_model(plate_image)  # âœ… è‡ªåŠ¨é¢„å¤„ç†
```

### æ­¥éª¤4: æ›´æ–°ç»“æœè§£æ

```python
# æ—§ç‰ˆ
text_index = outputs['text_index']
results = decode(character, text_index)

# æ–°ç‰ˆ
text, conf, char_confs = results[0]  # âœ… è‡ªåŠ¨è§£ç 
```

### æ­¥éª¤5: åˆ é™¤æ—§ç‰ˆå·¥å…·å‡½æ•°è°ƒç”¨

```python
# æ—§ç‰ˆ
from utils.ocr_image_processing import process_plate_image
processed = process_plate_image(img, True)

# æ–°ç‰ˆ(å¦‚æœç¡®å®éœ€è¦ç‹¬ç«‹è°ƒç”¨)
processed = OCRONNX._process_plate_image_static(img, is_double_layer=True)

# æˆ–æ›´æ¨è:ç›´æ¥ä½¿ç”¨å®Œæ•´æ¨ç†
results, _ = ocr_model(img, is_double_layer=True)
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å»ºè®®1: å¤ç”¨æ¨¡å‹å®ä¾‹

```python
# âŒ ä¸æ¨è:æ¯æ¬¡éƒ½åˆ›å»ºæ–°å®ä¾‹
def process_plate(plate_img):
    ocr_model = OCRONNX('models/ocr.onnx', character)  # æ¯æ¬¡éƒ½é‡æ–°åŠ è½½æ¨¡å‹
    return ocr_model(plate_img)

# âœ… æ¨è:å¤ç”¨å®ä¾‹
ocr_model = OCRONNX('models/ocr.onnx', character)  # åˆå§‹åŒ–ä¸€æ¬¡

def process_plate(plate_img):
    return ocr_model(plate_img)  # å¤ç”¨å®ä¾‹,å¿«é€Ÿæ¨ç†
```

**æ€§èƒ½æå‡**: é¿å…é‡å¤æ¨¡å‹åŠ è½½,èŠ‚çœ~500msåˆå§‹åŒ–æ—¶é—´

### å»ºè®®2: ä½¿ç”¨TensorRTå¼•æ“

```python
# æ­¥éª¤1: æ„å»ºTensorRTå¼•æ“(ä¸€æ¬¡æ€§æ“ä½œ)
from tools.build_engine import build_engine

build_engine(
    onnx_path='models/ocr.onnx',
    engine_path='models/ocr.engine',
    fp16=True  # ä½¿ç”¨FP16ç²¾åº¦
)

# æ­¥éª¤2: åŠ è½½TensorRTå¼•æ“(è€Œä¸æ˜¯ONNX)
ocr_model = OCRONNX(
    onnx_path='models/ocr.engine',  # âœ… ä½¿ç”¨.engineæ–‡ä»¶
    character=character
)

# æ¨ç†é€Ÿåº¦æå‡2-3å€
results, _ = ocr_model(plate_img)
```

**æ€§èƒ½æå‡**: OCRæ¨ç†æ—¶é—´ä»~20msé™ä½åˆ°~8ms (GPU)

### å»ºè®®3: è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼

```python
# æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´é˜ˆå€¼
ocr_model = OCRONNX(
    'models/ocr.onnx',
    character=character,
    conf_thres=0.7  # âœ… æé«˜é˜ˆå€¼,å‡å°‘è¯¯è¯†åˆ«
)

# æˆ–åœ¨æ¨ç†æ—¶åŠ¨æ€è°ƒæ•´
high_conf_results, _ = ocr_model(plate_img, conf_thres=0.9)
```

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜1: å¯¼å…¥é”™è¯¯

```python
# é”™è¯¯ä¿¡æ¯
ImportError: cannot import name 'OCRONNX' from 'infer_onnx.ocr_onnx'

# åŸå› :æ—§ç‰ˆå¯¼å…¥è·¯å¾„
from infer_onnx.ocr_onnx import OCRONNX  # âŒ

# è§£å†³:ä½¿ç”¨æ–°ç‰ˆå¯¼å…¥
from infer_onnx import OCRONNX  # âœ…
```

### é—®é¢˜2: ç¼ºå°‘å¿…éœ€å‚æ•°

```python
# é”™è¯¯ä¿¡æ¯
TypeError: __init__() missing 1 required positional argument: 'character'

# åŸå› :æ–°ç‰ˆéœ€è¦characterå‚æ•°
ocr_model = OCRONNX('models/ocr.onnx')  # âŒ

# è§£å†³:æ·»åŠ characterå‚æ•°
ocr_model = OCRONNX('models/ocr.onnx', character=character)  # âœ…
```

### é—®é¢˜3: è¿”å›æ ¼å¼å˜åŒ–

```python
# é”™è¯¯ä¿¡æ¯
TypeError: cannot unpack non-iterable dict object

# åŸå› :ColorLayerONNXè¿”å›æ ¼å¼å˜åŒ–
color, layer = classifier(plate_img)  # âŒ æ—§ç‰ˆè¿”å›å…ƒç»„

# è§£å†³:ä½¿ç”¨å­—å…¸è®¿é—®
result, _ = classifier(plate_img)
color = result['color']  # âœ… æ–°ç‰ˆè¿”å›å­—å…¸
layer = result['layer']
```

### é—®é¢˜4: æ‰¾ä¸åˆ°é™æ€æ–¹æ³•

```python
# é”™è¯¯ä¿¡æ¯
AttributeError: 'OCRONNX' object has no attribute 'process_plate_image'

# åŸå› :æ–¹æ³•åå˜åŒ–
OCRONNX.process_plate_image(img)  # âŒ

# è§£å†³:ä½¿ç”¨æ–°çš„é™æ€æ–¹æ³•å
OCRONNX._process_plate_image_static(img, is_double_layer=True)  # âœ…
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### OCRONNXæ€§èƒ½æŒ‡æ ‡

| æ“ä½œ | æ—§ç‰ˆ (v1.0) | æ–°ç‰ˆ (v2.0) | æ”¹è¿› |
|------|-------------|-------------|------|
| åˆå§‹åŒ–æ—¶é—´ | ~800ms | ~50ms | **93.8%** (æ‡’åŠ è½½) |
| é¢„å¤„ç†æ—¶é—´ | ~6ms | ~4ms | **33.3%** |
| æ¨ç†æ—¶é—´ (ONNX) | ~22ms | ~20ms | **9.1%** |
| åå¤„ç†æ—¶é—´ | ~3ms | ~2ms | **33.3%** |
| æ€»æ—¶é—´ (é¦–æ¬¡) | ~831ms | ~76ms | **90.9%** |
| æ€»æ—¶é—´ (åç»­) | ~31ms | ~26ms | **16.1%** |

### ColorLayerONNXæ€§èƒ½æŒ‡æ ‡

| æ“ä½œ | æ—§ç‰ˆ (v1.0) | æ–°ç‰ˆ (v2.0) | æ”¹è¿› |
|------|-------------|-------------|------|
| åˆå§‹åŒ–æ—¶é—´ | ~600ms | ~30ms | **95.0%** |
| é¢„å¤„ç†æ—¶é—´ | ~3ms | ~2ms | **33.3%** |
| æ¨ç†æ—¶é—´ (ONNX) | ~12ms | ~10ms | **16.7%** |
| åå¤„ç†æ—¶é—´ | ~2ms | ~1ms | **50.0%** |
| æ€»æ—¶é—´ (é¦–æ¬¡) | ~617ms | ~43ms | **93.0%** |
| æ€»æ—¶é—´ (åç»­) | ~17ms | ~13ms | **23.5%** |

**æµ‹è¯•ç¯å¢ƒ**: RTX 3090, CUDA 11.8, batch_size=1

---

## ğŸ¯ æœ€ä½³å®è·µæ€»ç»“

### âœ… æ¨èåšæ³•

1. **ä½¿ç”¨ç»Ÿä¸€çš„`__call__()`æ¥å£**
   ```python
   results, _ = ocr_model(plate_img)  # âœ… ç®€æ´æ˜äº†
   ```

2. **å¤ç”¨æ¨¡å‹å®ä¾‹**
   ```python
   ocr_model = OCRONNX(...)  # åˆå§‹åŒ–ä¸€æ¬¡
   for img in images:
       results, _ = ocr_model(img)  # å¤šæ¬¡è°ƒç”¨
   ```

3. **ä½¿ç”¨é…ç½®æ–‡ä»¶ç®¡ç†å‚æ•°**
   ```python
   with open('configs/plate.yaml') as f:
       config = yaml.safe_load(f)
   ocr_model = OCRONNX(..., character=config['plate_dict']['character'])
   ```

4. **åˆ©ç”¨ç±»å‹æç¤ºæé«˜ä»£ç è´¨é‡**
   ```python
   from typing import List, Tuple
   from numpy.typing import NDArray
   import numpy as np

   def recognize_plate(
       img: NDArray[np.uint8],
       ocr: OCRONNX
   ) -> Tuple[str, float]:
       results, _ = ocr(img)
       return results[0][:2]  # (text, confidence)
   ```

### âŒ é¿å…çš„åšæ³•

1. **ä¸è¦æ··ç”¨æ—§ç‰ˆå’Œæ–°ç‰ˆAPI**
   ```python
   # âŒ æ··ä¹±çš„ä»£ç 
   from utils.ocr_image_processing import process_plate_image
   preprocessed = process_plate_image(img)
   results, _ = ocr_model(preprocessed)  # é‡å¤é¢„å¤„ç†
   ```

2. **ä¸è¦é‡å¤åˆ›å»ºæ¨¡å‹å®ä¾‹**
   ```python
   # âŒ æ€§èƒ½å·®
   for img in images:
       ocr = OCRONNX(...)  # æ¯æ¬¡éƒ½é‡æ–°åŠ è½½æ¨¡å‹
       results, _ = ocr(img)
   ```

3. **ä¸è¦å¿½ç•¥ç½®ä¿¡åº¦é˜ˆå€¼**
   ```python
   # âŒ å¯èƒ½äº§ç”Ÿä½è´¨é‡ç»“æœ
   ocr_model = OCRONNX(..., conf_thres=0.1)  # é˜ˆå€¼è¿‡ä½
   ```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å®Œæ•´APIåˆçº¦](./contracts/ocr_onnx_api.yaml) - OCRONNXè¯¦ç»†APIè§„èŒƒ
- [å®Œæ•´APIåˆçº¦](./contracts/color_layer_onnx_api.yaml) - ColorLayerONNXè¯¦ç»†APIè§„èŒƒ
- [æ•°æ®æ¨¡å‹å®šä¹‰](./data-model.md) - å®Œæ•´çš„ç±»ç»“æ„å’Œç±»å‹å®šä¹‰
- [æŠ€æœ¯ç ”ç©¶æŠ¥å‘Š](./research.md) - è®¾è®¡å†³ç­–å’ŒæŠ€æœ¯è°ƒç ”
- [å®æ–½è®¡åˆ’](./plan.md) - åˆ†é˜¶æ®µå®æ–½è®¡åˆ’

---

## ğŸ”„ ç‰ˆæœ¬å…¼å®¹æ€§

| ç‰ˆæœ¬ | çŠ¶æ€ | æ”¯æŒåˆ° | è¯´æ˜ |
|------|------|--------|------|
| v2.0 | âœ… å½“å‰ | - | é‡æ„åç‰ˆæœ¬,æ¨èä½¿ç”¨ |
| v1.0 | âš ï¸ å·²å¼ƒç”¨ | 2025-12-31 | æ—§ç‰ˆç‹¬ç«‹å®ç°,è®¡åˆ’ç§»é™¤ |

---

*æœ€åæ›´æ–°: 2025-10-09*
*å¯¹åº”spec: specs/004-refactor-colorlayeronnx-ocronnx/spec.md*
