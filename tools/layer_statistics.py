#!/usr/bin/env python3
"""
å±‚ç»Ÿè®¡å·¥å…· - ä½¿ç”¨ Polygraphy ç°æˆå‡½æ•°

è¯¥è„šæœ¬ä½¿ç”¨ Polygraphy åº“çš„ç°æˆå‡½æ•°æ¥åˆ†æ ONNX æ¨¡å‹å’Œ TensorRT ç½‘ç»œä¸­çš„æ‰€æœ‰å±‚å’Œå¼ é‡ä¿¡æ¯ï¼Œ
æ¨¡æ‹Ÿ --onnx-outputs mark all å’Œ --trt-outputs mark all çš„è¡Œä¸ºã€‚

ä½¿ç”¨æ–¹æ³•:
    python layer_statistics.py --model model.onnx
    python layer_statistics.py --model model.onnx --build-trt
    python layer_statistics.py --model model.onnx --save-json stats.json
"""

import argparse
import json
import sys
from collections import defaultdict
from pathlib import Path
from typing import Any, Dict, List, Optional

try:
    from polygraphy.backend.onnx import ModifyOutputs, OnnxFromPath
    from polygraphy.backend.onnx.util import all_tensor_names, get_num_nodes
    from polygraphy.constants import MARK_ALL
    print("âœ… Polygraphy ONNX åç«¯å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ Polygraphy ONNX åç«¯å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    import tensorrt as trt
    from polygraphy.backend.trt import ModifyNetworkOutputs, NetworkFromOnnxPath
    from polygraphy.backend.trt.util import get_all_tensors
    TRT_AVAILABLE = True
    print("âœ… Polygraphy TensorRT åç«¯å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸  Polygraphy TensorRT åç«¯ä¸å¯ç”¨: {e}")
    TRT_AVAILABLE = False

try:
    import onnx
    print("âœ… ONNX åº“å¯¼å…¥æˆåŠŸ")
except ImportError:
    print("âŒ éœ€è¦å®‰è£… onnx åº“: pip install onnx")
    sys.exit(1)


class PolygraphyONNXAnalyzer:
    """ä½¿ç”¨ Polygraphy ONNX åç«¯çš„åˆ†æå™¨"""

    def __init__(self, model_path: str):
        self.model_path = model_path
        self.onnx_model = None
        self.load_model()

    def load_model(self):
        """ä½¿ç”¨ Polygraphy åŠ è½½ ONNX æ¨¡å‹"""
        try:
            # ä½¿ç”¨ Polygraphy çš„ OnnxFromPath åŠ è½½æ¨¡å‹
            loader = OnnxFromPath(self.model_path)
            self.onnx_model = loader()
            print(f"âœ… ä½¿ç”¨ Polygraphy æˆåŠŸåŠ è½½ ONNX æ¨¡å‹: {self.model_path}")
        except Exception as e:
            print(f"âŒ ä½¿ç”¨ Polygraphy åŠ è½½ ONNX æ¨¡å‹å¤±è´¥: {e}")
            sys.exit(1)

    def get_all_tensor_names_with_polygraphy(self) -> Dict[str, List[str]]:
        """ä½¿ç”¨ Polygraphy çš„ all_tensor_names å‡½æ•°è·å–å¼ é‡åç§°"""
        # è·å–æ‰€æœ‰éå¸¸é‡å¼ é‡ï¼ˆä¸åŒ…å«è¾“å…¥ï¼‰
        all_outputs = all_tensor_names(self.onnx_model, include_inputs=False)

        # è·å–åŒ…å«è¾“å…¥çš„æ‰€æœ‰å¼ é‡
        all_outputs_with_inputs = all_tensor_names(self.onnx_model, include_inputs=True)

        # è·å–è¾“å…¥å¼ é‡åç§°
        input_names = [inp.name for inp in self.onnx_model.graph.input]

        # è·å–è¾“å‡ºå¼ é‡åç§°
        output_names = [out.name for out in self.onnx_model.graph.output]

        return {
            'non_constant_tensors': all_outputs,  # mark all æ ‡è®°çš„å¼ é‡
            'all_tensors_with_inputs': all_outputs_with_inputs,
            'input_tensors': input_names,
            'output_tensors': output_names
        }

    def analyze_with_mark_all(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿ --onnx-outputs mark all çš„è¡Œä¸º"""
        try:
            # ä½¿ç”¨ ModifyOutputs å’Œ MARK_ALL æ¥æ¨¡æ‹Ÿ mark all è¡Œä¸º
            modify_loader = ModifyOutputs(
                OnnxFromPath(self.model_path),
                outputs=MARK_ALL
            )
            modified_model = modify_loader()

            print(f"âœ… ä½¿ç”¨ ModifyOutputs(outputs=MARK_ALL) æˆåŠŸä¿®æ”¹æ¨¡å‹")

            # è·å–ä¿®æ”¹åçš„è¾“å‡ºå¼ é‡
            modified_output_names = [out.name for out in modified_model.graph.output]

            return {
                'original_outputs_count': len([out.name for out in self.onnx_model.graph.output]),
                'mark_all_outputs_count': len(modified_output_names),
                'mark_all_output_names': modified_output_names
            }

        except Exception as e:
            print(f"âŒ ModifyOutputs æ“ä½œå¤±è´¥: {e}")
            return {}

    def analyze_model_info(self) -> Dict[str, Any]:
        """åˆ†ææ¨¡å‹åŸºæœ¬ä¿¡æ¯"""
        stats = {
            'model_info': {
                'model_path': self.model_path,
                'ir_version': self.onnx_model.ir_version,
                'producer_name': self.onnx_model.producer_name,
                'producer_version': self.onnx_model.producer_version
            },
            'graph_info': {
                'name': self.onnx_model.graph.name,
                'total_nodes': len(self.onnx_model.graph.node),
                'total_inputs': len(self.onnx_model.graph.input),
                'total_outputs': len(self.onnx_model.graph.output),
                'total_initializers': len(self.onnx_model.graph.initializer)
            }
        }

        # ä½¿ç”¨ Polygraphy çš„ get_num_nodes å‡½æ•°
        try:
            polygraphy_node_count = get_num_nodes(self.onnx_model)
            stats['polygraphy_node_count'] = polygraphy_node_count
        except Exception as e:
            print(f"âš ï¸  get_num_nodes è°ƒç”¨å¤±è´¥: {e}")

        # å¼ é‡åˆ†æ
        tensor_info = self.get_all_tensor_names_with_polygraphy()
        stats['tensor_analysis'] = {
            'mark_all_tensor_count': len(tensor_info['non_constant_tensors']),
            'mark_all_tensor_names': tensor_info['non_constant_tensors'],
            'all_tensors_count': len(tensor_info['all_tensors_with_inputs']),
            'input_tensor_names': tensor_info['input_tensors'],
            'output_tensor_names': tensor_info['output_tensors']
        }

        # mark all è¡Œä¸ºåˆ†æ
        mark_all_info = self.analyze_with_mark_all()
        stats['mark_all_analysis'] = mark_all_info

        # å±‚ç±»å‹ç»Ÿè®¡
        layer_types = defaultdict(int)
        for node in self.onnx_model.graph.node:
            layer_types[node.op_type] += 1

        stats['layer_types'] = dict(layer_types)
        stats['most_common_layers'] = sorted(layer_types.items(), key=lambda x: x[1], reverse=True)[:10]

        return stats


class PolygraphyTensorRTAnalyzer:
    """ä½¿ç”¨ Polygraphy TensorRT åç«¯çš„åˆ†æå™¨"""

    def __init__(self, model_path: str):
        if not TRT_AVAILABLE:
            raise ImportError("TensorRT ä¸å¯ç”¨")

        self.model_path = model_path
        self.network_info = None
        self.setup_network()

    def setup_network(self):
        """ä½¿ç”¨ Polygraphy æ„å»º TensorRT ç½‘ç»œ"""
        try:
            # ä½¿ç”¨ Polygraphy çš„ NetworkFromOnnxPath æ„å»ºç½‘ç»œ
            network_loader = NetworkFromOnnxPath(self.model_path)
            builder, network, parser = network_loader()

            self.network_info = {
                'builder': builder,
                'network': network,
                'parser': parser
            }

            print(f"âœ… ä½¿ç”¨ Polygraphy NetworkFromOnnxPath æˆåŠŸæ„å»º TensorRT ç½‘ç»œ")

        except Exception as e:
            print(f"âŒ ä½¿ç”¨ Polygraphy æ„å»º TensorRT ç½‘ç»œå¤±è´¥: {e}")
            raise

    def get_all_tensors_with_polygraphy(self) -> Dict[str, Any]:
        """ä½¿ç”¨ Polygraphy çš„ get_all_tensors å‡½æ•°è·å–å¼ é‡ä¿¡æ¯"""
        network = self.network_info['network']

        # ä½¿ç”¨ Polygraphy çš„ get_all_tensors å‡½æ•°
        all_tensors = get_all_tensors(network)

        # æŒ‰ç…§å±‚çš„é¡ºåºæ”¶é›†å¼ é‡ä¿¡æ¯
        ordered_tensor_names = []
        tensor_info = {}

        # éå†æ¯ä¸€å±‚ï¼ŒæŒ‰é¡ºåºæ”¶é›†å¼ é‡
        for layer_idx in range(network.num_layers):
            layer = network.get_layer(layer_idx)

            # æ”¶é›†è¿™ä¸€å±‚çš„è¾“å…¥å¼ é‡
            for i in range(layer.num_inputs):
                tensor = layer.get_input(i)
                if tensor is not None and tensor.name in all_tensors:
                    if tensor.name not in tensor_info:  # é¿å…é‡å¤
                        ordered_tensor_names.append(tensor.name)
                        tensor_info[tensor.name] = {
                            'name': tensor.name,
                            'shape': tuple(tensor.shape) if hasattr(tensor, 'shape') else None,
                            'dtype': str(tensor.dtype) if hasattr(tensor, 'dtype') else None,
                            'layer_index': layer_idx,
                            'tensor_type': 'input'
                        }

            # æ”¶é›†è¿™ä¸€å±‚çš„è¾“å‡ºå¼ é‡
            for i in range(layer.num_outputs):
                tensor = layer.get_output(i)
                if tensor is not None and tensor.name in all_tensors:
                    if tensor.name not in tensor_info:  # é¿å…é‡å¤
                        ordered_tensor_names.append(tensor.name)
                        tensor_info[tensor.name] = {
                            'name': tensor.name,
                            'shape': tuple(tensor.shape) if hasattr(tensor, 'shape') else None,
                            'dtype': str(tensor.dtype) if hasattr(tensor, 'dtype') else None,
                            'layer_index': layer_idx,
                            'tensor_type': 'output'
                        }

        # æ·»åŠ ä»»ä½•é—æ¼çš„å¼ é‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        for name, tensor in all_tensors.items():
            if name not in tensor_info:
                ordered_tensor_names.append(name)
                tensor_info[name] = {
                    'name': name,
                    'shape': tuple(tensor.shape) if hasattr(tensor, 'shape') else None,
                    'dtype': str(tensor.dtype) if hasattr(tensor, 'dtype') else None,
                    'layer_index': -1,  # æœªçŸ¥å±‚
                    'tensor_type': 'unknown'
                }

        return {
            'tensor_count': len(all_tensors),
            'tensor_names': ordered_tensor_names,  # ç°åœ¨æ˜¯æœ‰åºçš„
            'tensor_details': tensor_info
        }

    def analyze_with_mark_all(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿ --trt-outputs mark all çš„è¡Œä¸º"""
        try:
            network = self.network_info['network']

            # ä½¿ç”¨ ModifyNetworkOutputs å’Œ MARK_ALL
            modify_network_loader = ModifyNetworkOutputs(
                NetworkFromOnnxPath(self.model_path),
                outputs=MARK_ALL
            )

            builder, modified_network, parser = modify_network_loader()

            # è·å–ä¿®æ”¹åçš„è¾“å‡ºä¿¡æ¯
            original_output_count = network.num_outputs
            modified_output_count = modified_network.num_outputs

            modified_output_names = []
            for i in range(modified_output_count):
                output_tensor = modified_network.get_output(i)
                modified_output_names.append(output_tensor.name)

            print(f"âœ… ä½¿ç”¨ ModifyNetworkOutputs(outputs=MARK_ALL) æˆåŠŸä¿®æ”¹ TensorRT ç½‘ç»œ")

            return {
                'original_outputs_count': original_output_count,
                'mark_all_outputs_count': modified_output_count,
                'mark_all_output_names': modified_output_names
            }

        except Exception as e:
            print(f"âŒ ModifyNetworkOutputs æ“ä½œå¤±è´¥: {e}")
            return {}

    def analyze_network_info(self) -> Dict[str, Any]:
        """åˆ†æ TensorRT ç½‘ç»œä¿¡æ¯"""
        network = self.network_info['network']

        stats = {
            'network_info': {
                'name': network.name,
                'num_layers': network.num_layers,
                'num_inputs': network.num_inputs,
                'num_outputs': network.num_outputs
            }
        }

        # å¼ é‡åˆ†æ
        tensor_info = self.get_all_tensors_with_polygraphy()
        stats['tensor_analysis'] = tensor_info

        # mark all è¡Œä¸ºåˆ†æ
        mark_all_info = self.analyze_with_mark_all()
        stats['mark_all_analysis'] = mark_all_info

        # å±‚ç±»å‹ç»Ÿè®¡
        layer_types = defaultdict(int)
        for i in range(network.num_layers):
            layer = network.get_layer(i)
            layer_type = str(layer.type).split('.')[-1]
            layer_types[layer_type] += 1

        stats['layer_types'] = dict(layer_types)
        stats['most_common_layers'] = sorted(layer_types.items(), key=lambda x: x[1], reverse=True)[:10]

        # è¾“å…¥è¾“å‡ºä¿¡æ¯
        input_info = []
        for i in range(network.num_inputs):
            input_tensor = network.get_input(i)
            input_info.append({
                'name': input_tensor.name,
                'shape': tuple(input_tensor.shape),
                'dtype': str(input_tensor.dtype)
            })

        output_info = []
        for i in range(network.num_outputs):
            output_tensor = network.get_output(i)
            output_info.append({
                'name': output_tensor.name,
                'shape': tuple(output_tensor.shape),
                'dtype': str(output_tensor.dtype)
            })

        stats['input_info'] = input_info
        stats['output_info'] = output_info

        return stats


def print_analysis_summary(onnx_stats: Dict[str, Any], trt_stats: Optional[Dict[str, Any]] = None):
    """æ‰“å°åˆ†ææ‘˜è¦"""
    print("\n" + "="*80)
    print("ğŸ“Š Polygraphy å±‚ç»Ÿè®¡åˆ†ææŠ¥å‘Š")
    print("="*80)

    # ONNX åˆ†æç»“æœ
    print(f"\nğŸ”¹ ONNX æ¨¡å‹åˆ†æ (ä½¿ç”¨ Polygraphy ONNX åç«¯):")
    print(f"   æ¨¡å‹è·¯å¾„: {onnx_stats['model_info']['model_path']}")
    print(f"   æ€»èŠ‚ç‚¹æ•°: {onnx_stats['graph_info']['total_nodes']}")

    if 'polygraphy_node_count' in onnx_stats:
        print(f"   Polygraphy èŠ‚ç‚¹è®¡æ•°: {onnx_stats['polygraphy_node_count']}")

    print(f"   è¾“å…¥æ•°é‡: {onnx_stats['graph_info']['total_inputs']}")
    print(f"   åŸå§‹è¾“å‡ºæ•°é‡: {onnx_stats['graph_info']['total_outputs']}")

    # mark all è¡Œä¸ºåˆ†æ
    if onnx_stats.get('mark_all_analysis'):
        mark_all = onnx_stats['mark_all_analysis']
        if mark_all:
            print(f"   ğŸ“Œ --onnx-outputs mark all æ•ˆæœ:")
            print(f"      åŸå§‹è¾“å‡ºæ•°é‡: {mark_all.get('original_outputs_count', 'N/A')}")
            print(f"      mark all åè¾“å‡ºæ•°é‡: {mark_all.get('mark_all_outputs_count', 'N/A')}")

    # å¼ é‡åˆ†æ
    tensor_analysis = onnx_stats['tensor_analysis']
    print(f"\n   ğŸ“Œ all_tensor_names() å‡½æ•°ç»“æœ:")
    print(f"      mark all æ ‡è®°çš„å¼ é‡æ•°: {tensor_analysis['mark_all_tensor_count']}")
    print(f"      æ€»å¼ é‡æ•°(å«è¾“å…¥): {tensor_analysis['all_tensors_count']}")

    print(f"\n   å‰10ä¸ª mark all å¼ é‡:")
    for i, name in enumerate(tensor_analysis['mark_all_tensor_names'][:10]):
        print(f"      {i+1:2d}. {name}")
    if len(tensor_analysis['mark_all_tensor_names']) > 10:
        print(f"      ... è¿˜æœ‰ {len(tensor_analysis['mark_all_tensor_names']) - 10} ä¸ªå¼ é‡")

    print(f"\n   æœ€å¸¸è§å±‚ç±»å‹:")
    for layer_type, count in onnx_stats['most_common_layers'][:5]:
        print(f"      â€¢ {layer_type}: {count}")

    # TensorRT åˆ†æç»“æœ
    if trt_stats:
        print(f"\nğŸ”¹ TensorRT ç½‘ç»œåˆ†æ (ä½¿ç”¨ Polygraphy TensorRT åç«¯):")
        print(f"   ç½‘ç»œåç§°: {trt_stats['network_info']['name']}")
        print(f"   æ€»å±‚æ•°: {trt_stats['network_info']['num_layers']}")
        print(f"   è¾“å…¥æ•°é‡: {trt_stats['network_info']['num_inputs']}")
        print(f"   åŸå§‹è¾“å‡ºæ•°é‡: {trt_stats['network_info']['num_outputs']}")

        # mark all è¡Œä¸ºåˆ†æ
        if trt_stats.get('mark_all_analysis'):
            mark_all = trt_stats['mark_all_analysis']
            if mark_all:
                print(f"   ğŸ“Œ --trt-outputs mark all æ•ˆæœ:")
                print(f"      åŸå§‹è¾“å‡ºæ•°é‡: {mark_all.get('original_outputs_count', 'N/A')}")
                print(f"      mark all åè¾“å‡ºæ•°é‡: {mark_all.get('mark_all_outputs_count', 'N/A')}")

        # å¼ é‡åˆ†æ
        tensor_analysis = trt_stats['tensor_analysis']
        print(f"\n   ğŸ“Œ get_all_tensors() å‡½æ•°ç»“æœ:")
        print(f"      æ€»å¼ é‡æ•°: {tensor_analysis['tensor_count']}")

        print(f"\n   å‰10ä¸ªå¼ é‡:")
        for i, name in enumerate(tensor_analysis['tensor_names'][:10]):
            print(f"      {i+1:2d}. {name}")
        if len(tensor_analysis['tensor_names']) > 10:
            print(f"      ... è¿˜æœ‰ {len(tensor_analysis['tensor_names']) - 10} ä¸ªå¼ é‡")

        print(f"\n   æœ€å¸¸è§å±‚ç±»å‹:")
        for layer_type, count in trt_stats['most_common_layers'][:5]:
            print(f"      â€¢ {layer_type}: {count}")


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Polygraphy ç°æˆå‡½æ•°åˆ†ææ¨¡å‹å±‚ç»Ÿè®¡ä¿¡æ¯",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python layer_statistics.py --model model.onnx
  python layer_statistics.py --model model.onnx --build-trt
  python layer_statistics.py --model model.onnx --save-json
  python layer_statistics.py --model model.onnx --build-trt --save-json
        """
    )

    parser.add_argument(
        "--model", "-m",
        required=True,
        help="ONNX æ¨¡å‹æ–‡ä»¶è·¯å¾„"
    )

    parser.add_argument(
        "--build-trt",
        action="store_true",
        help="åŒæ—¶æ„å»º TensorRT ç½‘ç»œè¿›è¡Œåˆ†æ"
    )

    parser.add_argument(
        "--save-json",
        action="store_true",
        help="å°†ç»Ÿè®¡ç»“æœä¿å­˜ä¸º JSON æ–‡ä»¶åˆ° runs/{model_name}/ ç›®å½•"
    )

    args = parser.parse_args()

    if not Path(args.model).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        sys.exit(1)

    try:
        # ONNX åˆ†æ
        print("ğŸ”„ æ­£åœ¨ä½¿ç”¨ Polygraphy åˆ†æ ONNX æ¨¡å‹...")
        onnx_analyzer = PolygraphyONNXAnalyzer(args.model)
        onnx_stats = onnx_analyzer.analyze_model_info()

        # TensorRT åˆ†æ
        trt_stats = None
        if args.build_trt:
            if not TRT_AVAILABLE:
                print("âš ï¸  TensorRT ä¸å¯ç”¨ï¼Œè·³è¿‡ TensorRT åˆ†æ")
            else:
                print("ğŸ”„ æ­£åœ¨ä½¿ç”¨ Polygraphy æ„å»ºå’Œåˆ†æ TensorRT ç½‘ç»œ...")
                try:
                    trt_analyzer = PolygraphyTensorRTAnalyzer(args.model)
                    trt_stats = trt_analyzer.analyze_network_info()
                except Exception as e:
                    print(f"âš ï¸  TensorRT åˆ†æå¤±è´¥: {e}")

        # æ‰“å°åˆ†æç»“æœ
        print_analysis_summary(onnx_stats, trt_stats)

        # ä¿å­˜ JSON æ–‡ä»¶
        if args.save_json:
            # è·å–æ¨¡å‹åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰
            model_name = Path(args.model).stem
            output_dir = Path("runs") / model_name
            output_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜ ONNX åˆ†æç»“æœ
            onnx_file = output_dir / "onnx_layers.json"
            onnx_result = {
                'analysis_method': 'Polygraphy ONNX åç«¯',
                'model_path': args.model,
                'analysis': onnx_stats
            }

            with open(onnx_file, 'w', encoding='utf-8') as f:
                json.dump(onnx_result, f, ensure_ascii=False, indent=2, default=str)

            print(f"\nğŸ’¾ ONNX åˆ†æç»“æœå·²ä¿å­˜åˆ°: {onnx_file}")

            # ä¿å­˜ TensorRT åˆ†æç»“æœ
            if trt_stats:
                trt_file = output_dir / "trt_layers.json"
                trt_result = {
                    'analysis_method': 'Polygraphy TensorRT åç«¯',
                    'model_path': args.model,
                    'analysis': trt_stats
                }

                with open(trt_file, 'w', encoding='utf-8') as f:
                    json.dump(trt_result, f, ensure_ascii=False, indent=2, default=str)

                print(f"ğŸ’¾ TensorRT åˆ†æç»“æœå·²ä¿å­˜åˆ°: {trt_file}")

            print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir.absolute()}")

        print(f"\nâœ… åˆ†æå®Œæˆ!")
        print(f"\nğŸ’¡ å…³é”®å‘ç°:")
        print(f"   â€¢ ONNX mark all ä¼šæ ‡è®° {onnx_stats['tensor_analysis']['mark_all_tensor_count']} ä¸ªå¼ é‡ä¸ºè¾“å‡º")
        if trt_stats:
            print(f"   â€¢ TensorRT mark all ä¼šæ ‡è®° {trt_stats['tensor_analysis']['tensor_count']} ä¸ªå¼ é‡ä¸ºè¾“å‡º")

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
