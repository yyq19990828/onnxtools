# Polygraphy å¸¸è§é—®é¢˜è§£ç­” (FAQ)

æœ¬æ–‡æ¡£æ”¶é›†äº†ä½¿ç”¨ Polygraphy è¿‡ç¨‹ä¸­æœ€å¸¸é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆã€‚

## ğŸš€ å®‰è£…å’Œç¯å¢ƒé—®é¢˜

### Q1: å¦‚ä½•å®‰è£… Polygraphyï¼Ÿ
**A:** æ¨èé€šè¿‡ pip å®‰è£…ï¼š
```bash
pip install polygraphy
```

å¯¹äºå¼€å‘ç‰ˆæœ¬ï¼š
```bash
git clone https://github.com/NVIDIA/TensorRT.git
cd TensorRT/tools/Polygraphy
make install  # Linux
# æˆ– .\install.ps1  # Windows
```

### Q2: æç¤ºç¼ºå°‘ä¾èµ–æ€ä¹ˆåŠï¼Ÿ
**A:** è®¾ç½®è‡ªåŠ¨å®‰è£…ä¾èµ–ï¼š
```bash
export POLYGRAPHY_AUTOINSTALL_DEPS=1
polygraphy run model.onnx --onnxrt --trt
```

æˆ–æ‰‹åŠ¨å®‰è£…å¸¸ç”¨ä¾èµ–ï¼š
```bash
pip install onnx onnxruntime tensorrt
```

### Q3: åœ¨ Docker ç¯å¢ƒä¸­ä½¿ç”¨æ³¨æ„äº‹é¡¹ï¼Ÿ
**A:** ç¡®ä¿ Docker å®¹å™¨æœ‰ GPU è®¿é—®æƒé™ï¼š
```bash
docker run --gpus all -it nvcr.io/nvidia/tensorrt:22.12-py3
pip install polygraphy
```

## ğŸ”§ æ¨¡å‹è½¬æ¢é—®é¢˜

### Q4: ONNX è½¬ TensorRT å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
**A:** æŒ‰ä»¥ä¸‹æ­¥éª¤æ’æŸ¥ï¼š

1. **æ£€æŸ¥æ¨¡å‹æœ‰æ•ˆæ€§**ï¼š
```bash
polygraphy inspect model model.onnx
polygraphy check lint model.onnx
```

2. **æ¸…ç†æ¨¡å‹**ï¼š
```bash
polygraphy surgeon sanitize model.onnx --fold-constants --output clean.onnx
```

3. **æ£€æŸ¥ TensorRT å…¼å®¹æ€§**ï¼š
```bash
polygraphy inspect model clean.onnx --convert-to trt --verbose
```

4. **ä½¿ç”¨è¯¦ç»†æ—¥å¿—**ï¼š
```bash
polygraphy convert clean.onnx --convert-to trt --verbose --extra-verbose --output debug.engine
```

### Q5: åŠ¨æ€å½¢çŠ¶æ¨¡å‹è½¬æ¢é—®é¢˜ï¼Ÿ
**A:** æ˜ç¡®æŒ‡å®šæ‰€æœ‰å½¢çŠ¶å‚æ•°ï¼š
```bash
polygraphy convert model.onnx --convert-to trt \
  --trt-min-shapes input:[1,3,224,224] \
  --trt-opt-shapes input:[4,3,224,224] \
  --trt-max-shapes input:[8,3,224,224] \
  --output dynamic.engine
```

### Q6: INT8 é‡åŒ–å¤±è´¥æ€ä¹ˆè§£å†³ï¼Ÿ
**A:** å¸¸è§åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š

1. **æ ¡å‡†æ•°æ®ä¸è¶³æˆ–è´¨é‡å·®**ï¼š
```python
# ä½¿ç”¨æ›´å¤šä»£è¡¨æ€§æ•°æ®
def load_data():
    for i in range(500):  # å¢åŠ åˆ°500å¼ 
        # ä½¿ç”¨çœŸå®æ•°æ®è€Œééšæœºæ•°æ®
        yield {"input": preprocess_real_image(f"image_{i}.jpg")}
```

2. **æŸäº›å±‚ä¸æ”¯æŒ INT8**ï¼š
```bash
polygraphy convert model.onnx --convert-to trt --int8 \
  --precision-constraints sensitive_layer:fp16 \
  --calibration-cache calib.cache
```

### Q7: å†…å­˜ä¸è¶³é”™è¯¯ï¼Ÿ
**A:** å‡å°‘å†…å­˜å ç”¨ï¼š
```bash
# å‡å°‘å·¥ä½œç©ºé—´
polygraphy convert model.onnx --convert-to trt --workspace 512M

# ä½¿ç”¨æ›´å°çš„æœ€å¤§å½¢çŠ¶
polygraphy convert model.onnx --convert-to trt \
  --trt-max-shapes input:[4,3,224,224]  # é™ä½æ‰¹æ¬¡å¤§å°

# åˆ†æ‰¹å¤„ç†å¤§æ¨¡å‹
polygraphy surgeon extract model.onnx --inputs input --outputs intermediate
```

## ğŸ¯ ç²¾åº¦å’Œæ¨ç†é—®é¢˜

### Q8: è·¨æ¡†æ¶ç²¾åº¦ä¸åŒ¹é…ï¼Ÿ
**A:** åˆ†å±‚è°ƒè¯•æ­¥éª¤ï¼š

1. **è°ƒæ•´å®¹å·®**ï¼š
```bash
polygraphy run model.onnx --onnxrt --trt --rtol 1e-3 --atol 1e-3
```

2. **é€å±‚æ¯”è¾ƒ**ï¼š
```bash
polygraphy run model.onnx --onnxrt --trt --mark-all --save-outputs layer_outputs.json
```

3. **ä½¿ç”¨ç›¸åŒç²¾åº¦**ï¼š
```bash
polygraphy run model.onnx --onnxrt --trt --tf32  # ç¦ç”¨æ··åˆç²¾åº¦
```

4. **å‡å°‘é—®é¢˜æ¨¡å‹**ï¼š
```bash
polygraphy debug reduce model.onnx --output minimal_problem.onnx
```

### Q9: NaN æˆ– Inf è¾“å‡ºé—®é¢˜ï¼Ÿ
**A:** æ£€æŸ¥å’Œä¿®å¤æ­¥éª¤ï¼š

1. **æ£€æŸ¥è¾“å…¥æ•°æ®**ï¼š
```bash
polygraphy inspect data inputs.json --show-values --statistics
```

2. **æ£€æŸ¥æƒé‡**ï¼š
```bash
polygraphy inspect model model.onnx --show-weights --mode=full
```

3. **ä½¿ç”¨æ•°å€¼ç¨³å®šçš„é…ç½®**ï¼š
```bash
polygraphy convert model.onnx --convert-to trt --fp16 --tf32
```

### Q10: æ¨ç†é€Ÿåº¦æ…¢ï¼Ÿ
**A:** æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š

1. **ä½¿ç”¨ FP16**ï¼š
```bash
polygraphy convert model.onnx --convert-to trt --fp16
```

2. **å¢åŠ å·¥ä½œç©ºé—´**ï¼š
```bash
polygraphy convert model.onnx --convert-to trt --workspace 4G
```

3. **ä¼˜åŒ–åŠ¨æ€å½¢çŠ¶**ï¼š
```bash
# è®¾ç½®åˆé€‚çš„ opt-shapes
polygraphy convert model.onnx --convert-to trt \
  --trt-opt-shapes input:[typical_batch,3,224,224]
```

4. **ä½¿ç”¨ç­–ç•¥ç¼“å­˜**ï¼š
```bash
polygraphy convert model.onnx --convert-to trt \
  --save-tactics tactics.cache  # ç¬¬ä¸€æ¬¡æ„å»º
polygraphy convert model.onnx --convert-to trt \
  --load-tactics tactics.cache  # åç»­æ„å»º
```

## ğŸ› ï¸ è°ƒè¯•å’Œå¼€å‘é—®é¢˜

### Q11: å¦‚ä½•è°ƒè¯•å¤æ‚çš„ç²¾åº¦é—®é¢˜ï¼Ÿ
**A:** ç³»ç»Ÿæ€§è°ƒè¯•æµç¨‹ï¼š

1. **ç¡®è®¤é—®é¢˜èŒƒå›´**ï¼š
```bash
polygraphy run model.onnx --onnxrt --trt --save-outputs results.json
```

2. **å‡å°‘æ¨¡å‹**ï¼š
```bash
polygraphy debug reduce model.onnx --mode=bisect --output reduced.onnx
```

3. **è¯¦ç»†åˆ†æ**ï¼š
```bash
polygraphy debug precision reduced.onnx \
  --golden-outputs onnxrt_outputs.json \
  --mark-all --save-layer-outputs analysis.json
```

4. **å°è¯•ä¿®å¤**ï¼š
```bash
# ä¸ºé—®é¢˜å±‚æ·»åŠ ç²¾åº¦çº¦æŸ
polygraphy convert reduced.onnx --convert-to trt \
  --precision-constraints problematic_layer:fp16
```

### Q12: é—´æ­‡æ€§æ¨ç†å¤±è´¥ï¼Ÿ
**A:** å¯èƒ½æ˜¯ TensorRT ç­–ç•¥é—®é¢˜ï¼š

1. **å¤šæ¬¡æ„å»ºæµ‹è¯•**ï¼š
```bash
polygraphy debug build model.onnx --num-iterations 10 --save-tactics multiple.json
```

2. **åˆ†æç­–ç•¥å·®å¼‚**ï¼š
```bash
polygraphy debug diff-tactics build1.json build2.json
```

3. **æ’é™¤é—®é¢˜ç­–ç•¥**ï¼š
```bash
polygraphy convert model.onnx --convert-to trt \
  --exclude-tactics bad_tactics.json
```

### Q13: å¦‚ä½•å¤„ç†è‡ªå®šä¹‰ç®—å­ï¼Ÿ
**A:** è‡ªå®šä¹‰ç®—å­å¤„ç†æ–¹æ³•ï¼š

1. **æ£€æŸ¥ç®—å­æ”¯æŒ**ï¼š
```bash
polygraphy inspect model model.onnx --convert-to trt --verbose
```

2. **ä½¿ç”¨æ’ä»¶**ï¼š
```python
# æ³¨å†Œè‡ªå®šä¹‰æ’ä»¶
import tensorrt as trt
trt.init_libnvinfer_plugins(None, "")
```

3. **æ›¿æ¢ä¸æ”¯æŒçš„ç®—å­**ï¼š
```bash
# ä½¿ç”¨ surgeon æ›¿æ¢æˆ–ç§»é™¤ç®—å­
polygraphy surgeon prune model.onnx --remove-node-types CustomOp
```

## ğŸ“Š æ•°æ®å’Œæ ¼å¼é—®é¢˜

### Q14: è¾“å…¥æ•°æ®æ ¼å¼ä¸åŒ¹é…ï¼Ÿ
**A:** æ•°æ®é¢„å¤„ç†æ£€æŸ¥ï¼š

1. **æ£€æŸ¥æ¨¡å‹è¾“å…¥è¦æ±‚**ï¼š
```bash
polygraphy inspect model model.onnx --mode=basic
```

2. **éªŒè¯è¾“å…¥æ•°æ®**ï¼š
```python
import numpy as np
# ç¡®ä¿æ•°æ®ç±»å‹åŒ¹é…
input_data = input_data.astype(np.float32)
# ç¡®ä¿å½¢çŠ¶åŒ¹é…
assert input_data.shape == expected_shape
```

3. **ä½¿ç”¨æ•°æ®åŠ è½½å™¨è„šæœ¬**ï¼š
```python
def load_data():
    # ç¡®ä¿é¢„å¤„ç†æ­¥éª¤æ­£ç¡®
    image = cv2.imread("image.jpg")
    image = cv2.resize(image, (224, 224))
    image = image.transpose(2, 0, 1)  # HWC -> CHW
    image = image / 255.0  # å½’ä¸€åŒ–
    yield {"input": image[np.newaxis, :].astype(np.float32)}
```

### Q15: æ¨¡å‹è¾“å‡ºç»“æœå¼‚å¸¸ï¼Ÿ
**A:** è¾“å‡ºéªŒè¯æ­¥éª¤ï¼š

1. **æ£€æŸ¥è¾“å‡ºèŒƒå›´**ï¼š
```bash
polygraphy inspect data outputs.json --statistics --show-values
```

2. **ä¸å‚è€ƒç»“æœæ¯”è¾ƒ**ï¼š
```bash
polygraphy inspect diff expected.json actual.json --rtol=1e-3
```

3. **æ£€æŸ¥åå¤„ç†æ­¥éª¤**ï¼š
```python
# ç¡®ä¿åå¤„ç†é€»è¾‘æ­£ç¡®
outputs = model_inference(inputs)
results = postprocess(outputs)  # æ£€æŸ¥è¿™ä¸€æ­¥
```

## ğŸ” é«˜çº§ç”¨æ³•é—®é¢˜

### Q16: å¦‚ä½•æ‰¹é‡å¤„ç†å¤šä¸ªæ¨¡å‹ï¼Ÿ
**A:** æ‰¹é‡å¤„ç†è„šæœ¬ç¤ºä¾‹ï¼š

```bash
#!/bin/bash
for model in models/*.onnx; do
    echo "å¤„ç†: $model"
    model_name=$(basename "$model" .onnx)
    
    # éªŒè¯æ¨¡å‹
    polygraphy check lint "$model" || continue
    
    # è½¬æ¢æ¨¡å‹
    polygraphy convert "$model" --convert-to trt \
      --fp16 --workspace 2G \
      --output "engines/${model_name}.engine"
    
    # éªŒè¯ç²¾åº¦
    polygraphy run "$model" --onnxrt \
      --trt-engine "engines/${model_name}.engine" \
      --save-outputs "results/${model_name}.json"
done
```

### Q17: å¦‚ä½•é›†æˆåˆ° CI/CD æµæ°´çº¿ï¼Ÿ
**A:** CI/CD é›†æˆç¤ºä¾‹ï¼š

```yaml
# GitHub Actions ç¤ºä¾‹
- name: Model Validation
  run: |
    for model in changed_models/*.onnx; do
      # åŸºç¡€éªŒè¯
      polygraphy check lint "$model" || exit 1
      
      # å…¼å®¹æ€§æ£€æŸ¥
      polygraphy check compatibility "$model" --onnxrt || exit 1
      
      # æ€§èƒ½åŸºå‡†ï¼ˆå¯é€‰ï¼‰
      timeout 300 polygraphy convert "$model" --convert-to trt --workspace 1G || echo "TRT conversion timeout"
    done
```

### Q18: å¦‚ä½•ä¼˜åŒ–å¤§æ‰¹é‡æ¨ç†æ€§èƒ½ï¼Ÿ
**A:** å¤§æ‰¹é‡æ¨ç†ä¼˜åŒ–ï¼š

1. **ä½¿ç”¨åˆé€‚çš„æ‰¹æ¬¡å¤§å°**ï¼š
```bash
# æ‰¾åˆ°æœ€ä¼˜æ‰¹æ¬¡å¤§å°
for bs in 1 2 4 8 16; do
    polygraphy run model.onnx --trt \
      --input-shapes input:[$bs,3,224,224] \
      --warm-up-runs 10
done
```

2. **å¯ç”¨å¤šæµå¤„ç†**ï¼š
```python
# TensorRT å¤šæµæ¨ç†
context.set_optimization_profile(0)
stream1 = cuda.Stream()
stream2 = cuda.Stream()
```

3. **ä½¿ç”¨å†…å­˜æ± **ï¼š
```bash
polygraphy convert model.onnx --convert-to trt --pooled-outputs
```

## âš ï¸ æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è§é”™è¯¯ä¿¡æ¯åŠè§£å†³æ–¹æ¡ˆ

| é”™è¯¯ä¿¡æ¯ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|----------|----------|----------|
| `ONNX model is invalid` | ONNX æ¨¡å‹æŸå | `polygraphy check lint model.onnx` |
| `Unsupported operator` | TensorRT ä¸æ”¯æŒçš„ç®—å­ | æ£€æŸ¥ç®—å­å…¼å®¹æ€§æˆ–ä½¿ç”¨æ’ä»¶ |
| `Out of memory` | GPU å†…å­˜ä¸è¶³ | å‡å°‘æ‰¹æ¬¡å¤§å°æˆ–å·¥ä½œç©ºé—´ |
| `Calibration failed` | INT8 æ ¡å‡†æ•°æ®é—®é¢˜ | æ£€æŸ¥æ ¡å‡†æ•°æ®è´¨é‡å’Œæ•°é‡ |
| `Shape mismatch` | è¾“å…¥å½¢çŠ¶ä¸åŒ¹é… | æ£€æŸ¥æ¨¡å‹è¾“å…¥è¦æ±‚å’Œå®é™…æ•°æ®å½¢çŠ¶ |

### è·å–æ›´å¤šå¸®åŠ©

1. **è¯¦ç»†æ—¥å¿—**ï¼š
```bash
polygraphy <command> --verbose --extra-verbose --log-file debug.log
```

2. **å®˜æ–¹èµ„æº**ï¼š
   - [GitHub Issues](https://github.com/NVIDIA/TensorRT/issues)
   - [å®˜æ–¹æ–‡æ¡£](https://docs.nvidia.com/deeplearning/tensorrt/polygraphy/docs/)
   - [TensorRT å¼€å‘è€…è®ºå›](https://forums.developer.nvidia.com/c/accelerated-computing/deep-learning/tensorrt/)

3. **ç¤¾åŒºæ”¯æŒ**ï¼š
   - Stack Overflow (æ ‡ç­¾: `tensorrt`, `polygraphy`)
   - NVIDIA å¼€å‘è€…ç¤¾åŒº

---

*è¿™ä¸ª FAQ ä¼šæŒç»­æ›´æ–°ï¼Œå¦‚æœé‡åˆ°æ–°é—®é¢˜ï¼Œæ¬¢è¿é€šè¿‡ GitHub Issues åé¦ˆã€‚*